#!/bin/bash


########################################
# ///                                        \\\
#  		You can edit your configuration here
#
#
########################################
# megThreads=1500
# megWordlist=/root/Wordlist/endpoint/meg.txt
# meg_randomfile="/root/OneDrive/output/meg/randompath.txt"


massdnsWordlist=/root/Wordlist/subdomain/726w_subdomain.txt
ffuf_Wordlist=/root/Wordlist/endpoint/10w_common.txt





chromiumPath=/snap/bin/chromium
rootPath=/root/OneDrive/output/lazyrecon

########################################
# Happy Hunting
########################################






red=`tput setaf 1`
green=`tput setaf 2`
yellow=`tput setaf 3`
reset=`tput sgr0`

SECONDS=0


usage() { echo -e "Usage: $0 -d domain [-e]\n  Select -e to specify excluded domains\n " 1>&2; exit 1; }

while getopts ":d:e:r:" o; do
    case "${o}" in
        d)
            domain=${OPTARG}
            ;;

            #### working on subdomain exclusion
        e)
            excluded=${OPTARG}
            ;;

        *)
            usage
            ;;
    esac
done
shift $((OPTIND - 1))


discovery(){

  waybackrecon
  checkjsfile

memento_mass -f $rootPath/$domain/$foldername/responsiveDomains_final.txt  -o $rootPath/$domain/$foldername/wayback-data/robots_archieve.txt
  cp $rootPath/$domain/$foldername/wayback-data/robots_archieve.txt /var/www/jsrecon/links/$domain/urls/robots_archieve.txt

  portscanning
  eyewitnesser


}


checkjsfile(){
  mkdir -p $rootPath/$domain/$foldername/html
  wget2 -i $rootPath/$domain/$foldername/wayback-data/jsurls.txt -P $rootPath/$domain/$foldername/wayback-data/jsfile
  mkdir -p $rootPath/$domain/$foldername/wayback-data/jsfile
  cd $rootPath/$domain/$foldername/wayback-data/jsfile
  ls -v | cat -n | while read n f; do mv -n "$f" "$n.ext"; done
  python3  ~/recon_tools/LinkFinder/linkfinder.py -i './*'   -o $rootPath/$domain/$foldername/html/${domain}_js.html
  python3  ~/recon_tools/LinkFinder/linkfinder.py -i './*'  -r /api/   -o $rootPath/$domain/$foldername/html/${domain}_js_api.html
  cd -

  mkdir -p /var/www/jsrecon/links/$domain
  cp $rootPath/$domain/$foldername/html/${domain}_js.html /var/www/jsrecon/links/$domain/${domain}_js.html
  cp $rootPath/$domain/$foldername/html/${domain}_js_api.html /var/www/jsrecon/links/$domain/${domain}_js_api.html

}

waybackrecon () {
echo "Scraping wayback for data..."
cat $rootPath/$domain/$foldername/responsiveDomains_final.txt  | gau > $rootPath/$domain/$foldername/wayback-data/waybackurls.txt
cat $rootPath/$domain/$foldername/wayback-data/waybackurls.txt  | sort -u | unfurl --unique keys > $rootPath/$domain/$foldername/wayback-data/paramlist.txt
[ -s $rootPath/$domain/$foldername/wayback-data/paramlist.txt ] && echo "Wordlist saved to /$domain/$foldername/wayback-data/paramlist.txt"

mkdir -p /var/www/jsrecon/links/$domain/urls


python3 $rootPath/$domain/$foldername/wayback-data/waybackurls.txt /var/www/jsrecon/links/$domain/urls/waybackurls.html


cat $rootPath/$domain/$foldername/wayback-data/waybackurls.txt  | sort -u | grep -P "\w+\.js(\?|$)" | sort -u > $rootPath/$domain/$foldername/wayback-data/jsurls.txt
[ -s $rootPath/$domain/$foldername/wayback-data/jsurls.txt ] && echo "JS Urls saved to /$domain/$foldername/wayback-data/jsurls.txt"

cat $rootPath/$domain/$foldername/wayback-data/waybackurls.txt  | sort -u | grep -P "\w+\.php(\?|$) "| sort -u > $rootPath/$domain/$foldername/wayback-data/phpurls.txt
[ -s $rootPath/$domain/$foldername/wayback-data/phpurls.txt ] && echo "PHP Urls saved to /$domain/$foldername/wayback-data/phpurls.txt"

cat $rootPath/$domain/$foldername/wayback-data/waybackurls.txt  | sort -u | grep -P "\w+\.aspx(\?|$) "| sort -u  > $rootPath/$domain/$foldername/wayback-data/aspxurls.txt
[ -s $rootPath/$domain/$foldername/wayback-data/aspxurls.txt ] && echo "ASP Urls saved to /$domain/$foldername/wayback-data/aspxurls.txt"

cat $rootPath/$domain/$foldername/wayback-data/waybackurls.txt  | sort -u | grep -P "\w+\.jsp(\?|$) "| sort -u  > $rootPath/$domain/$foldername/wayback-data/jspurls.txt
[ -s $rootPath/$domain/$foldername/wayback-data/jspurls.txt ] && echo "JSP Urls saved to /$domain/$foldername/wayback-data/jspurls.txt"

cp -r $rootPath/$domain/$foldername/wayback-data/ /var/www/jsrecon/links/$domain/urls/

}


hostalive(){
echo "Probing for live hosts..."
cat $rootPath/$domain/$foldername/massdns_checked_subdomains.txt  | httprobe -c 50 -t 3000 > $rootPath/$domain/$foldername/responsive_urls.txt

cat $rootPath/$domain/$foldername/responsive_urls.txt |unfurl -unique domain > $rootPath/$domain/$foldername/responsiveDomains.txt

count=$(wc -l $rootPath/$domain/$foldername/responsiveDomains.txt | awk '{print $1}')

if [[ $count = 0 ]]; then
  exit 1
fi

echo  "${yellow}Total of ${count} live subdomains were found${reset}"
}



recon(){

  echo "${green}Recon started on $domain ${reset}"
  echo "Listing subdomains using assertfinder..."
  assetfinder --subs-only $domain > $rootPath/$domain/$foldername/raw_subdomains.txt

  number=$(wc -l $rootPath/$domain/$foldername/raw_subdomains.txt| awk '{print $1}')
  if [[ $number -le 3 ]]; then
    ffuf -w $ffuf_Wordlist   -u https://${domain}/FUZZ -se -fs 0 -fw 1  > $rootPath/$domain/$foldername/${domain}_output.txt
    ip=$(dig +short $line @8.8.8.8| grep -m 1 -o '[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}')
    printf "${ip}" > $rootPath/$domain/$foldername/only_ip.txt
    ipport_mass -f  $rootPath/$domain/$foldername/only_ip.txt -o $rootPath/$domain/$foldername/portscanning
    echo "Fininshed ffuf scanning   " | mutt -s "FFUF_full ${domain}"  inthebybyby@gmail.com  -a $rootPath/$domain/$foldername/${domain}_output.txt
    exit 1
  fi



  echo "Checking Passive source with massdns"
  massdns_second_check


  echo "Starting Massdns Subdomain discovery this may take a while"
  mass $domain > /dev/null
  echo "Massdns finished..."

  rm_dup_file $rootPath/$domain/$foldername/massdns_checked_subdomains.txt


  hostalive

  using_dnsgen
  hostalive_for_dnsgen

  cat $rootPath/$domain/$foldername/responsive_urls.txt >> $rootPath/$domain/$foldername/responsive_urls_final.txt

  rm_dup_file $rootPath/$domain/$foldername/responsive_urls_final.txt

  cat $rootPath/$domain/$foldername/responsive_urls_final.txt |unfurl -unique domain > $rootPath/$domain/$foldername/responsiveDomains_final.txt

  python3 /root/recon_tools/Scripts/python/urls_processing.py  $rootPath/$domain/$foldername/responsive_urls_final.txt  $rootPath/$domain/$foldername/ffuf_input.txt

  nsrecords $domain

  rm_dup_file $rootPath/$domain/$foldername/${domain}_subdomains_nmap.txt

}



# test_meg(){
#   echo "filtering url which will return 200 status for any endpoint..."
#
#   meg -c $megThreads --savestatus 200  $meg_randomfile  $rootPath/$domain/$foldername/responsive_urls.txt $rootPath/$domain/$foldername/meg/remove  2>&1 | tee $rootPath/$domain/$foldername/meg/remove/error_hosts
#   find $rootPath/$domain/$foldername/meg/remove  -mindepth 1 -maxdepth 1 -type d -print0 | xargs -0 rm -R
#    awk '{print $2}'  $rootPath/$domain/$foldername/meg/remove/index | awk -F[/:] '{print $1"://"$4}' | awk '!seen[$0]++'  > $rootPath/$domain/$foldername/meg/remove/host_to_remove
#   awk '{print $4}'  $rootPath/$domain/$foldername/meg/remove/error_hosts | awk -F[/:] '{print $1"://"$4}'| sort | uniq -c | sort -nr | awk '$1>3 {print $2}'|awk '!seen[$0]++' >> $rootPath/$domain/$foldername/meg/remove/host_to_remove
#   rm_dup_file $rootPath/$domain/$foldername/meg/remove/host_to_remove
#   comm -2 -3 <(sort $rootPath/$domain/$foldername/responsive_urls.txt ) <(sort $rootPath/$domain/$foldername/meg/remove/host_to_remove) > $rootPath/$domain/$foldername/meg/filtered_url.txt
# }
#
# run_meg(){
#   echo "Starting meg..."
#   meg -c $megThreads  --savestatus 200 $megWordlist $rootPath/$domain/$foldername/meg/filtered_url.txt  $rootPath/$domain/$foldername/meg/output  2>&1 | tee $rootPath/$domain/$foldername/meg/output/error.log
#   find $rootPath/$domain/$foldername/meg/output  -mindepth 1 -maxdepth 1 -type d -print0 | xargs -0 rm -R
#
# }
#
# meger(){
#   test_meg
#   run_meg
#
# }

#
# searchcrtsh(){
#
#  /root/recon_tools/massdns/scripts/ct.py $domain 2>/dev/null > $rootPath/$domain/$foldername/tmp.txt
#  [ -s $rootPath/$domain/$foldername/tmp.txt ] && cat $rootPath/$domain/$foldername/tmp.txt | massdns -r /root/Wordlist/resolver.txt -t A -q -o S -w  $rootPath/$domain/$foldername/crtsh.txt
#
#
# awk '{print $1}'  $rootPath/$domain/$foldername/crtsh.txt >> $rootPath/$domain/$foldername/raw_subdomains.txt
#
#
#  cat $rootPath/$domain/$foldername/crtsh.txt >> $rootPath/$domain/$foldername/useless/massdns_temp.txt
# }


eyewitnesser(){
  echo "Starting Eyewitness scan..."
  timeout 3h EyeWitness.py --web  --no-prompt  -f $rootPath/$domain/$foldername/responsive_urls_final.txt --timeout 30  -d $rootPath/$domain/$foldername/eyewitness
  cd $rootPath/$domain/$foldername/eyewitness/screens
  # fdupes . -r -f -1 -S -d
  cd -
	mv $rootPath/$domain/$foldername/eyewitness /var/www/jsrecon/links/$domain/

}





portscanning(){
  touch $rootPath/$domain/$foldername/domain_ip_tmp.txt
  while read line; do
     ip=$(dig +short $line @8.8.8.8| grep -m 1 -o '[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}')
     if [[ -z $ip ]]; then
       continue
     fi
     echo "$line     $ip" >>$rootPath/$domain/$foldername/domain_ip_tmp.txt
  done <  $rootPath/$domain/$foldername/${domain}_subdomains_nmap.txt

  cat $rootPath/$domain/$foldername/domain_ip_tmp.txt | awk '!seen[$2]++' > $rootPath/$domain/$foldername/domain_ip.txt

  rm $rootPath/$domain/$foldername/domain_ip_tmp.txt


  awk '{print $2}' $rootPath/$domain/$foldername/domain_ip.txt | awk '!seen[$0]++' > $rootPath/$domain/$foldername/only_ip.txt

ipport_mass -f  $rootPath/$domain/$foldername/only_ip.txt -o $rootPath/$domain/$foldername/portscanning

}

massdns_second_check(){
  cat $rootPath/$domain/$foldername/raw_subdomains.txt | massdns -r /root/Wordlist/resolver.txt -t A -q -o S -w  $rootPath/$domain/$foldername/useless/massdns_temp.txt

}


mass(){
/root/recon_tools/massdns/scripts/subbrute.py $massdnsWordlist $domain | massdns -r /root/Wordlist/resolver.txt -t A -q -o S > $rootPath/$domain/$foldername/useless/mass.txt


cat $rootPath/$domain/$foldername/useless/mass.txt >> $rootPath/$domain/$foldername/useless/massdns_temp.txt

rm $rootPath/$domain/$foldername/useless/mass.txt

deduplicate_massdns_output $rootPath/$domain/$foldername/useless/massdns_temp.txt

awk '{print $1}' $rootPath/$domain/$foldername/useless/massdns_temp.txt | sed 's/\.$//' > $rootPath/$domain/$foldername/massdns_checked_subdomains.txt

rm_dup_file $rootPath/$domain/$foldername/massdns_checked_subdomains.txt

cat $rootPath/$domain/$foldername/massdns_checked_subdomains.txt > $rootPath/$domain/$foldername/${domain}_subdomains_nmap.txt

}

deduplicate_massdns_output(){
tmpfile=/tmp/$(basename $1)
awk '!seen[$3]++' $1 > $tmpfile
mv $tmpfile $1
}

using_dnsgen(){
  echo "Using dnsgen..."

  head -n 1500 $rootPath/$domain/$foldername/responsiveDomains.txt | dnsgen - > $rootPath/$domain/$foldername/dnsgen_temp.txt

  rm_dup_file  $rootPath/$domain/$foldername/dnsgen_temp.txt

  cat $rootPath/$domain/$foldername/dnsgen_temp.txt | massdns -r /root/Wordlist/resolver.txt -t A -q -o S > $rootPath/$domain/$foldername/useless/dnsgen_mass.txt

  deduplicate_massdns_output $rootPath/$domain/$foldername/useless/dnsgen_mass.txt

  awk '{print $1}' $rootPath/$domain/$foldername/useless/dnsgen_mass.txt | sed 's/\.$//' > $rootPath/$domain/$foldername/dnsgen_resolved_domains.txt

    rm_dup_file  $rootPath/$domain/$foldername/dnsgen_resolved_domains.txt

  cat $rootPath/$domain/$foldername/dnsgen_resolved_domains.txt >>  $rootPath/$domain/$foldername/${domain}_subdomains_nmap.txt

  rm $rootPath/$domain/$foldername/dnsgen_temp.txt
}

hostalive_for_dnsgen(){
  cat $rootPath/$domain/$foldername/dnsgen_resolved_domains.txt | httprobe -c 50 -t 3000 > $rootPath/$domain/$foldername/useless/dnsgen_responsive.txt

  cat $rootPath/$domain/$foldername/useless/dnsgen_responsive.txt > $rootPath/$domain/$foldername/responsive_urls_final.txt

  rm_dup_file $rootPath/$domain/$foldername/responsive_urls_final.txt




}

nsrecords(){

                echo "${green}Started dns records check...${reset}"
                echo "Looking into CNAME Records..."





                cat $rootPath/$domain/$foldername/useless/massdns_temp.txt | grep CNAME >> $rootPath/$domain/$foldername/cnames.txt
                cat $rootPath/$domain/$foldername/useless/dnsgen_mass.txt | grep CNAME >> $rootPath/$domain/$foldername/cnames.txt


                cat $rootPath/$domain/$foldername/cnames.txt | sort -u | while read line; do
                hostrec=$(echo "$line" | awk '{print $1}')
                if [[ $(host $hostrec | grep NXDOMAIN) != "" ]]
                then
                echo "${red}Check the following domain for NS takeover:  $line ${reset}"
                echo "$line" >> $rootPath/$domain/$foldername/pos.txt
                else
                echo -ne "working on it...\r"
                fi
                done
                sleep 1

        }



logo(){
  #can't have a bash script without a cool logo :D
  echo "${red}
 _     ____  ____ ___  _ ____  _____ ____  ____  _
/ \   /  _ \/_   \\\  \///  __\/  __//   _\/  _ \/ \  /|
| |   | / \| /   / \  / |  \/||  \  |  /  | / \|| |\ ||
| |_/\| |-||/   /_ / /  |    /|  /_ |  \__| \_/|| | \||
\____/\_/ \|\____//_/   \_/\_\\\____\\\____/\____/\_/  \\|
${reset}                                                      "
}


main(){
  logo


  mkdir -p $rootPath/$domain
  mkdir -p $rootPath/$domain/$foldername
  mkdir -p $rootPath/$domain/$foldername/wayback-data/
  mkdir -p $rootPath/$domain/$foldername/eyewitness
  mkdir -p $rootPath/$domain/$foldername/useless
  touch $rootPath/$domain/$foldername/useless/mass.txt
  touch $rootPath/$domain/$foldername/cnames.txt
  touch $rootPath/$domain/$foldername/pos.txt
  touch $rootPath/$domain/$foldername/raw_subdomains.txt
  touch $rootPath/$domain/$foldername/useless/massdns_temp.txt
  touch $rootPath/$domain/$foldername/domaintemp.txt
  touch $rootPath/$domain/$foldername/useless/cleantemp.txt
  touch $rootPath/$domain/$foldername/${domain}_subdomains_nmap.txt

  rm_resolver
  recon

  echo "Starting discovery..."
  discovery

  mkdir -p $rootPath/$domain/$foldername/ffuf/

  ffuf_mass -f $rootPath/$domain/$foldername/ffuf_input.txt -o $rootPath/$domain/$foldername/ffuf/
  cp $rootPath/$domain/$foldername/ffuf/ffuf_output.html /var/www/jsrecon/links/$domain/ffuf_output.html
  echo "Fininshed ffuf scanning   " | mutt -s "FFUF_full ${domain}
  http://jsrecon.ragnarokv.site/links/${domain}/ffuf_output.html"  inthebybyby@gmail.com


  # -a $rootPath/$domain/$foldername/ffuf/ffuf_output.html




  echo "${green}Scan for $domain finished successfully${reset}"
  duration=$SECONDS
  echo "Scan completed in : $(($duration / 60)) minutes and $(($duration % 60)) seconds."
  stty sane
  tput sgr0
}

todate=$(date +'%Y-%m-%d-%H-%M')
path=$(pwd)
foldername=recon-$todate

export rootPath
export domain
export foldername


main $domain
